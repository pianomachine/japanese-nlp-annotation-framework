#!/usr/bin/env python3
"""
Show detailed annotation samples with Japanese text analysis
"""

import json

def show_detailed_samples():
    """Show detailed annotation samples with explanations."""
    print("ğŸ‡¯ğŸ‡µ Japanese NLP Annotation Framework - Sample Analysis")
    print("=" * 70)
    
    with open('datasets/sentiment/sample_annotations.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"ğŸ“Š Dataset Overview:")
    print(f"  Total Samples: {len(data['annotation_samples'])}")
    print(f"  Annotators: {len(data['dataset_info']['annotators'])}")
    print(f"  Inter-annotator Agreement: {data['dataset_info']['inter_annotator_agreement']['cohens_kappa']:.3f}")
    
    # Show each sample with detailed analysis
    for i, sample in enumerate(data['annotation_samples']):
        print(f"\n{'='*60}")
        print(f"ğŸ“ Sample {i+1}: {sample['text_id']}")
        print(f"{'='*60}")
        
        # Show full text
        print(f"ğŸ”¤ Original Text:")
        print(f"  {sample['text']}")
        
        # Show domain
        print(f"\nğŸ·ï¸  Domain: {sample['domain']}")
        
        # Show gold label
        print(f"\nâœ… Gold Standard Label: {sample['gold_label']}")
        
        # Show each annotator's judgment
        print(f"\nğŸ‘¥ Annotator Judgments:")
        labels = []
        confidences = []
        
        for annotator_id, annotation in sample['annotations'].items():
            labels.append(annotation['primary_label'])
            confidences.append(annotation['confidence'])
            
            print(f"  {annotator_id}:")
            print(f"    Primary Label: {annotation['primary_label']}")
            print(f"    Confidence: {annotation['confidence']:.3f}")
            if 'fine_grained' in annotation and annotation['fine_grained']:
                print(f"    Fine-grained: {annotation['fine_grained']}")
            if 'reasoning' in annotation:
                print(f"    Reasoning: {annotation['reasoning']}")
        
        # Agreement analysis
        unique_labels = len(set(labels))
        avg_confidence = sum(confidences) / len(confidences)
        
        print(f"\nğŸ“Š Agreement Analysis:")
        print(f"  Unique Labels: {unique_labels}")
        print(f"  Average Confidence: {avg_confidence:.3f}")
        
        if unique_labels == 1:
            print(f"  âœ… Perfect Agreement - All annotators agree")
        elif unique_labels == 2:
            print(f"  âš ï¸  Partial Disagreement - 2 different labels")
        else:
            print(f"  âŒ Major Disagreement - {unique_labels} different labels")
        
        # Show notes if available
        if 'notes' in sample:
            print(f"\nğŸ“ Notes: {sample['notes']}")
        
        # Japanese-specific analysis
        text = sample['text']
        print(f"\nğŸ‡¯ğŸ‡µ Japanese Language Analysis:")
        
        # Check for specific patterns
        if 'ï¼' in text or '!!' in text:
            print(f"  â€¢ Contains exclamation marks (often positive)")
        if 'ã€‚ã€‚ã€‚' in text or '...' in text:
            print(f"  â€¢ Contains ellipsis (often indicates hesitation/negative)")
        if 'ã§ã™' in text or 'ã¾ã™' in text:
            print(f"  â€¢ Uses polite form (keigo)")
        if '(ç¬‘)' in text or 'ï¼ˆç¬‘ï¼‰' in text:
            print(f"  â€¢ Contains (ç¬‘) - potential sarcasm marker")
        if 'ã¡ã‚‡ã£ã¨' in text:
            print(f"  â€¢ Contains 'ã¡ã‚‡ã£ã¨' - often softens criticism")
        if 'æ™®é€š' in text:
            print(f"  â€¢ Contains 'æ™®é€š' - neutral indicator")
        if 'æœ€æ‚ª' in text or 'æœ€é«˜' in text:
            print(f"  â€¢ Contains extreme expression")
        
        # Confidence assessment
        if avg_confidence > 0.9:
            print(f"  ğŸ¯ High confidence sample - clear sentiment")
        elif avg_confidence > 0.7:
            print(f"  ğŸ¤” Moderate confidence - some ambiguity")
        else:
            print(f"  â“ Low confidence - challenging case")
        
        print()

if __name__ == "__main__":
    show_detailed_samples()